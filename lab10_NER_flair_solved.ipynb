{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "139758_NER_flair_solved.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wykrywanie encji nazwanych z Flair\n",
        "\n",
        "To już ostatnie laboratoria zadaniowe, w związku z tym, jeśli znajdziecie chwilę wolnego czasu, wypełnijcie proszę ankietę: https://docs.google.com/forms/d/1rHPjpL70XdXRD-ILl3AHophPNUk0AhsFus1-mtkUPsI\n",
        "\n",
        "Pozwoli to mi poprawić laboratoria w przyszłości, z góry dziękuję :)\n",
        "\n",
        "# Flair\n",
        "\n",
        "Biblioteka Flair to bardzo popularne narzędzie do tagowania sekwencji. Zaintstalujmy ją"
      ],
      "metadata": {
        "id": "OcjJ-YZy5-Pl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flair"
      ],
      "metadata": {
        "id": "4inJhzI0wQmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a195708-05d8-40ef-aff9-b299c6205dd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flair\n",
            "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
            "\u001b[K     |████████████████████████████████| 401 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.64.0)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.11.0+cu113)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting hyperopt>=0.2.7\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 64.8 MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 57.5 MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from flair) (8.13.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown==4.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.0)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.19.3-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 61.5 MB/s \n",
            "\u001b[?25hCollecting conllu>=4.0\n",
            "  Downloading conllu-4.4.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (3.7.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==4.4.0->flair) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.14.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (6.0.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (2.6.3)\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.2.7->flair) (0.16.0)\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 20.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n",
            "Building wheels for collected packages: mpld3, overrides, sqlitedict, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=309b6625b7a852c5fc7f246820fcb86b9b7a7561f137c587806eebfdfe4e566c\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=7274d5b886822c8717876a3eead56cbb4ce07e4f1b0555633edd550cacffcfa4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=e7729c7aa2102a3c6ebe44c2e57e0a4d6cfa19e49a86e9043f89c6610577546d\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/dd/2e/0ed4a25cb73fc30c7ea8d10b50acb7226175736067e40a7ea3\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=f04201e6f74c93f673268589e7e88b74956e67c4b22ab3e5dac321b4fa12032e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=4bd85f3240b178f90fef3d430f389d7f0bacdc18fa6d1727bf76136dce292756\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=e514f058e9513b6ac61aee3ea8c50b8ace2ba866209a30667ff92b34536b41d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built mpld3 overrides sqlitedict langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, py4j, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, langdetect, konoha, janome, hyperopt, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.4\n",
            "    Uninstalling importlib-metadata-4.11.4:\n",
            "      Successfully uninstalled importlib-metadata-4.11.4\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 huggingface-hub-0.7.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.5 pyyaml-6.0 requests-2.28.0 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tokenizers-0.12.1 transformers-4.19.3 wikipedia-api-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPCJONALNE WSPARCIE DLA KART GRAFICZNYCH\n",
        "# W colabie możemy trenować z wykorzystaniem karty graficznej, dzięki temu trening działa dużo szybciej\n",
        "# Aby włączyć wsparcie dla karty graficznej musimy:\n",
        "# 1. w menu 'srodowisko wykonawcze' wybrać `zmien typ srodowiska wykonawczego` i tam `akcelerator sprzętowy` = GPU\n",
        "# 2. odkomentować linijki poniżej\n",
        "import flair, torch\n",
        "flair.device = torch.device('cuda:0') "
      ],
      "metadata": {
        "id": "0-maEaJD0Ojj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ładowanie zbioru danych i słownika z etykietami.\n",
        "\n",
        "**Zadanie1: (1 punkt):** Stwórz słownik etykiet z wczytanego korpusu korzystając z funkcji `make_label_dictionary()`. W naszym zbiorze, etykiety do wykrycia występują w kolumnie `ner`, której identyfikator został zapisany w linijce 6. Tutorial: https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md może okazać się pomocny.\n",
        "\n",
        "Efektem działania powinna być lista etykiet np: \n",
        "`Dictionary with 20 tags: <unk>, Variable, Class, Application, User_Interface_Element, Code_Block, Language, Function, Data_Structure, Library, Data_Type, File_Type, File_Name, Version, HTML_XML_Tag, Device, Operating_System, Website, User_Name, Algorithm`"
      ],
      "metadata": {
        "id": "AyApRy6G7YQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.datasets import NER_ENGLISH_STACKOVERFLOW    # zbiór otagowanych postów na Stacku\n",
        "\n",
        "corpus = NER_ENGLISH_STACKOVERFLOW().downsample(0.8)   # pobieramy korpus i zmniejszamy jego wielkość\n",
        "corpus.filter_empty_sentences()                         # usuwamy puste zdania\n",
        "\n",
        "label_type = 'ner'   # identyfikator pod którym możemy dostać typy etykiet\n",
        "label_dict = corpus.make_label_dictionary(label_type)    # TODO\n",
        "print('\\n\\nEtykiety do wykrycia')\n",
        "print(label_dict)"
      ],
      "metadata": {
        "id": "eK84adKF6GLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf5c22c-207e-4043-8635-03087cceb348"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:00:44,813 File train has 741 questions and 897 answers.\n",
            "2022-06-09 21:00:44,834 File test has 249 questions and 315 answers.\n",
            "2022-06-09 21:00:44,857 File dev has 247 questions and 289 answers.\n",
            "2022-06-09 21:00:44,858 Reading data from /root/.flair/datasets/ner_english_stackoverflow\n",
            "2022-06-09 21:00:44,862 Train: /root/.flair/datasets/ner_english_stackoverflow/train.txt\n",
            "2022-06-09 21:00:44,864 Dev: /root/.flair/datasets/ner_english_stackoverflow/dev.txt\n",
            "2022-06-09 21:00:44,867 Test: /root/.flair/datasets/ner_english_stackoverflow/test.txt\n",
            "2022-06-09 21:00:51,763 Filtering empty sentences\n",
            "2022-06-09 21:00:51,916 Corpus: 7410 train + 2349 dev + 2486 test sentences\n",
            "2022-06-09 21:00:51,918 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7410it [00:00, 49250.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:00:52,079 Dictionary created for label 'ner' with 21 values: Application (seen 1058 times), Class (seen 1047 times), Variable (seen 903 times), User_Interface_Element (seen 772 times), Code_Block (seen 675 times), Function (seen 605 times), Library (seen 593 times), Language (seen 575 times), Data_Structure (seen 507 times), Data_Type (seen 342 times), File_Type (seen 301 times), File_Name (seen 239 times), Version (seen 223 times), HTML_XML_Tag (seen 165 times), Device (seen 163 times), Operating_System (seen 148 times), Website (seen 86 times), User_Name (seen 71 times), Algorithm (seen 31 times), Licence (seen 1 times)\n",
            "\n",
            "\n",
            "Etykiety do wykrycia\n",
            "Dictionary with 21 tags: <unk>, Application, Class, Variable, User_Interface_Element, Code_Block, Function, Library, Language, Data_Structure, Data_Type, File_Type, File_Name, Version, HTML_XML_Tag, Device, Operating_System, Website, User_Name, Algorithm, Licence\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeddingi\n",
        "\n",
        "W narzędziu Flair możemy bardzo prosto składać ze sobą różne embeddingi. \n",
        "\n",
        "**Zad2 (2 punkty):** Zapoznaj się z działaniem `StackedEmbeddings` opisanego w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md i zbuduj embeddingi zawierające reprezentacje pochodzące zarówno z Glove jak i Flairowe, oparte na `news-forward`. "
      ],
      "metadata": {
        "id": "vlz60uuR83oR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yzCwq37iwFo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3e7d2e-e771-42ca-e624-40baeb344653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token[0]: \"The\"\n",
            "tensor([-3.8194e-02, -2.4487e-01,  7.2812e-01,  ..., -4.4014e-04,\n",
            "        -3.9301e-02,  1.0601e-02], device='cuda:0')\n",
            "Token[1]: \"grass\"\n",
            "tensor([-8.1353e-01,  9.4042e-01, -2.4048e-01,  ..., -3.7749e-04,\n",
            "        -2.3563e-02,  1.1700e-02], device='cuda:0')\n",
            "Token[2]: \"is\"\n",
            "tensor([-0.5426,  0.4148,  1.0322,  ..., -0.0061,  0.0112,  0.0100],\n",
            "       device='cuda:0')\n",
            "Token[3]: \"green\"\n",
            "tensor([-0.6791,  0.3491, -0.2398,  ..., -0.0026, -0.0118,  0.0455],\n",
            "       device='cuda:0')\n",
            "Token[4]: \".\"\n",
            "tensor([-3.3979e-01,  2.0941e-01,  4.6348e-01,  ..., -2.3405e-04,\n",
            "         3.8688e-03,  5.7725e-03], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from flair.embeddings import WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
        "from flair.data import Sentence\n",
        "\n",
        "sentence = Sentence('The grass is green .')\n",
        "\n",
        "glove_embedding = WordEmbeddings('glove')\n",
        "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
        "\n",
        "embeddings = StackedEmbeddings([glove_embedding,\n",
        "                               flair_embedding_forward])\n",
        "\n",
        "\n",
        "embeddings.embed(sentence)\n",
        "\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tagger i trainer\n",
        "\n",
        "**Zadanie 3 (2 punkty)** Bazując na treściach opisanych w https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md przygotuj obiekt `SequenceTagger`, którego rozmiar wartswy ukrytej wyniesie 256. Do obiektu tego przekażemy stworzone wcześniej embeddingi, słownik `label_dict` i nazwę kolumny z etykietą ze zmiennej `label_type`. Ustawmy `use_crf` na True.\n",
        "\n",
        "Przygotuj obiekt `ModelTrainer`, który przyjmie zarówno nasz korpus jak i stworzony przed chwilą `SequenceTagger`."
      ],
      "metadata": {
        "id": "6Wxgw7Uc91e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=label_dict,\n",
        "                        tag_type = label_type,\n",
        "                        use_crf = True)    \n",
        "trainer = ModelTrainer(tagger, corpus) \n",
        "\n",
        "\n",
        "#stworzony trainer możemy zacząć trenować!\n",
        "trainer.train('resources/taggers/example-upos',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=5)\n",
        "\n",
        "# a kiedy wytrenujemy, wczytujemy najlepszy model.\n",
        "model = SequenceTagger.load('resources/taggers/example-upos/final-model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aLW-cccQypy",
        "outputId": "14e4fcc8-5a93-46b7-f883-565e55fa9e1d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:19:53,587 SequenceTagger predicts: Dictionary with 81 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Function, B-Function, E-Function, I-Function, S-Library, B-Library, E-Library, I-Library, S-Language, B-Language, E-Language, I-Language, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-Version\n",
            "2022-06-09 21:19:53,695 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:19:53,696 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "        (decoder): Linear(in_features=2048, out_features=300, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=2148, out_features=2148, bias=True)\n",
            "  (rnn): LSTM(2148, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=83, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2022-06-09 21:19:53,699 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:19:53,703 Corpus: \"Corpus: 7410 train + 2349 dev + 2486 test sentences\"\n",
            "2022-06-09 21:19:53,705 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:19:53,708 Parameters:\n",
            "2022-06-09 21:19:53,711  - learning_rate: \"0.100000\"\n",
            "2022-06-09 21:19:53,712  - mini_batch_size: \"32\"\n",
            "2022-06-09 21:19:53,715  - patience: \"3\"\n",
            "2022-06-09 21:19:53,719  - anneal_factor: \"0.5\"\n",
            "2022-06-09 21:19:53,722  - max_epochs: \"5\"\n",
            "2022-06-09 21:19:53,724  - shuffle: \"True\"\n",
            "2022-06-09 21:19:53,727  - train_with_dev: \"False\"\n",
            "2022-06-09 21:19:53,730  - batch_growth_annealing: \"False\"\n",
            "2022-06-09 21:19:53,732 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:19:53,735 Model training base path: \"resources/taggers/example-upos\"\n",
            "2022-06-09 21:19:53,736 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:19:53,738 Device: cuda:0\n",
            "2022-06-09 21:19:53,740 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:19:53,742 Embeddings storage mode: cpu\n",
            "2022-06-09 21:19:53,745 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/flair/trainers/trainer.py:65: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  \"There should be no best model saved at epoch 1 except there \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:19:55,416 epoch 1 - iter 23/232 - loss 1.16432619 - samples/sec: 441.46 - lr: 0.100000\n",
            "2022-06-09 21:19:57,152 epoch 1 - iter 46/232 - loss 0.94032945 - samples/sec: 425.40 - lr: 0.100000\n",
            "2022-06-09 21:19:58,814 epoch 1 - iter 69/232 - loss 0.82986923 - samples/sec: 444.80 - lr: 0.100000\n",
            "2022-06-09 21:20:00,473 epoch 1 - iter 92/232 - loss 0.77080926 - samples/sec: 444.50 - lr: 0.100000\n",
            "2022-06-09 21:20:02,173 epoch 1 - iter 115/232 - loss 0.72141856 - samples/sec: 434.62 - lr: 0.100000\n",
            "2022-06-09 21:20:04,059 epoch 1 - iter 138/232 - loss 0.68696591 - samples/sec: 391.05 - lr: 0.100000\n",
            "2022-06-09 21:20:05,908 epoch 1 - iter 161/232 - loss 0.66625654 - samples/sec: 399.01 - lr: 0.100000\n",
            "2022-06-09 21:20:07,508 epoch 1 - iter 184/232 - loss 0.64227767 - samples/sec: 461.02 - lr: 0.100000\n",
            "2022-06-09 21:20:09,322 epoch 1 - iter 207/232 - loss 0.61886673 - samples/sec: 406.74 - lr: 0.100000\n",
            "2022-06-09 21:20:11,031 epoch 1 - iter 230/232 - loss 0.60621236 - samples/sec: 431.65 - lr: 0.100000\n",
            "2022-06-09 21:20:11,144 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:20:11,145 EPOCH 1 done: loss 0.6050 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:07<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:20:18,516 Evaluating as a multi-label problem: False\n",
            "2022-06-09 21:20:18,546 DEV : loss 0.42523738741874695 - f1-score (micro avg)  0.1507\n",
            "2022-06-09 21:20:18,773 BAD EPOCHS (no improvement): 0\n",
            "2022-06-09 21:20:18,777 saving best model\n",
            "2022-06-09 21:20:20,448 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:20:22,450 epoch 2 - iter 23/232 - loss 0.42329868 - samples/sec: 368.73 - lr: 0.100000\n",
            "2022-06-09 21:20:24,105 epoch 2 - iter 46/232 - loss 0.42224534 - samples/sec: 445.66 - lr: 0.100000\n",
            "2022-06-09 21:20:26,116 epoch 2 - iter 69/232 - loss 0.41555298 - samples/sec: 366.92 - lr: 0.100000\n",
            "2022-06-09 21:20:27,860 epoch 2 - iter 92/232 - loss 0.40708889 - samples/sec: 423.13 - lr: 0.100000\n",
            "2022-06-09 21:20:29,445 epoch 2 - iter 115/232 - loss 0.40738833 - samples/sec: 465.81 - lr: 0.100000\n",
            "2022-06-09 21:20:31,141 epoch 2 - iter 138/232 - loss 0.40221479 - samples/sec: 434.95 - lr: 0.100000\n",
            "2022-06-09 21:20:32,733 epoch 2 - iter 161/232 - loss 0.40420460 - samples/sec: 463.71 - lr: 0.100000\n",
            "2022-06-09 21:20:34,569 epoch 2 - iter 184/232 - loss 0.40236263 - samples/sec: 401.74 - lr: 0.100000\n",
            "2022-06-09 21:20:36,422 epoch 2 - iter 207/232 - loss 0.39825145 - samples/sec: 398.08 - lr: 0.100000\n",
            "2022-06-09 21:20:38,198 epoch 2 - iter 230/232 - loss 0.39584555 - samples/sec: 415.52 - lr: 0.100000\n",
            "2022-06-09 21:20:38,363 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:20:38,365 EPOCH 2 done: loss 0.3949 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:06<00:00, 11.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:20:44,814 Evaluating as a multi-label problem: False\n",
            "2022-06-09 21:20:44,852 DEV : loss 0.332430362701416 - f1-score (micro avg)  0.2797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:20:45,012 BAD EPOCHS (no improvement): 0\n",
            "2022-06-09 21:20:45,014 saving best model\n",
            "2022-06-09 21:20:46,102 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:20:48,071 epoch 3 - iter 23/232 - loss 0.34427851 - samples/sec: 375.61 - lr: 0.100000\n",
            "2022-06-09 21:20:49,933 epoch 3 - iter 46/232 - loss 0.35795542 - samples/sec: 396.15 - lr: 0.100000\n",
            "2022-06-09 21:20:51,774 epoch 3 - iter 69/232 - loss 0.35262696 - samples/sec: 400.93 - lr: 0.100000\n",
            "2022-06-09 21:20:53,490 epoch 3 - iter 92/232 - loss 0.34918944 - samples/sec: 429.86 - lr: 0.100000\n",
            "2022-06-09 21:20:55,064 epoch 3 - iter 115/232 - loss 0.34579990 - samples/sec: 468.83 - lr: 0.100000\n",
            "2022-06-09 21:20:56,768 epoch 3 - iter 138/232 - loss 0.34335658 - samples/sec: 433.44 - lr: 0.100000\n",
            "2022-06-09 21:20:58,537 epoch 3 - iter 161/232 - loss 0.34062201 - samples/sec: 416.99 - lr: 0.100000\n",
            "2022-06-09 21:21:00,300 epoch 3 - iter 184/232 - loss 0.34060470 - samples/sec: 418.94 - lr: 0.100000\n",
            "2022-06-09 21:21:02,057 epoch 3 - iter 207/232 - loss 0.34449595 - samples/sec: 420.28 - lr: 0.100000\n",
            "2022-06-09 21:21:03,919 epoch 3 - iter 230/232 - loss 0.34365218 - samples/sec: 396.37 - lr: 0.100000\n",
            "2022-06-09 21:21:04,065 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:21:04,066 EPOCH 3 done: loss 0.3440 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:07<00:00, 10.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:21:11,390 Evaluating as a multi-label problem: False\n",
            "2022-06-09 21:21:11,421 DEV : loss 0.28645655512809753 - f1-score (micro avg)  0.3668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:21:11,565 BAD EPOCHS (no improvement): 0\n",
            "2022-06-09 21:21:11,568 saving best model\n",
            "2022-06-09 21:21:12,657 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:21:14,385 epoch 4 - iter 23/232 - loss 0.31504298 - samples/sec: 428.37 - lr: 0.100000\n",
            "2022-06-09 21:21:16,198 epoch 4 - iter 46/232 - loss 0.31008216 - samples/sec: 406.91 - lr: 0.100000\n",
            "2022-06-09 21:21:18,004 epoch 4 - iter 69/232 - loss 0.31049884 - samples/sec: 408.76 - lr: 0.100000\n",
            "2022-06-09 21:21:19,970 epoch 4 - iter 92/232 - loss 0.31967387 - samples/sec: 375.29 - lr: 0.100000\n",
            "2022-06-09 21:21:21,787 epoch 4 - iter 115/232 - loss 0.31578998 - samples/sec: 406.02 - lr: 0.100000\n",
            "2022-06-09 21:21:23,472 epoch 4 - iter 138/232 - loss 0.31680196 - samples/sec: 437.88 - lr: 0.100000\n",
            "2022-06-09 21:21:25,241 epoch 4 - iter 161/232 - loss 0.31767834 - samples/sec: 417.09 - lr: 0.100000\n",
            "2022-06-09 21:21:27,054 epoch 4 - iter 184/232 - loss 0.31718550 - samples/sec: 407.02 - lr: 0.100000\n",
            "2022-06-09 21:21:28,829 epoch 4 - iter 207/232 - loss 0.31625274 - samples/sec: 415.66 - lr: 0.100000\n",
            "2022-06-09 21:21:30,511 epoch 4 - iter 230/232 - loss 0.31455539 - samples/sec: 438.53 - lr: 0.100000\n",
            "2022-06-09 21:21:30,634 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:21:30,636 EPOCH 4 done: loss 0.3153 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:06<00:00, 11.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:21:37,115 Evaluating as a multi-label problem: False\n",
            "2022-06-09 21:21:37,147 DEV : loss 0.2670557200908661 - f1-score (micro avg)  0.4015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:21:37,292 BAD EPOCHS (no improvement): 0\n",
            "2022-06-09 21:21:37,293 saving best model\n",
            "2022-06-09 21:21:38,358 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:21:40,088 epoch 5 - iter 23/232 - loss 0.31476223 - samples/sec: 427.19 - lr: 0.100000\n",
            "2022-06-09 21:21:41,797 epoch 5 - iter 46/232 - loss 0.29940697 - samples/sec: 431.85 - lr: 0.100000\n",
            "2022-06-09 21:21:43,517 epoch 5 - iter 69/232 - loss 0.30245237 - samples/sec: 428.94 - lr: 0.100000\n",
            "2022-06-09 21:21:45,248 epoch 5 - iter 92/232 - loss 0.30459716 - samples/sec: 426.26 - lr: 0.100000\n",
            "2022-06-09 21:21:46,973 epoch 5 - iter 115/232 - loss 0.30277315 - samples/sec: 427.74 - lr: 0.100000\n",
            "2022-06-09 21:21:48,731 epoch 5 - iter 138/232 - loss 0.30226365 - samples/sec: 419.71 - lr: 0.100000\n",
            "2022-06-09 21:21:50,648 epoch 5 - iter 161/232 - loss 0.30208785 - samples/sec: 384.75 - lr: 0.100000\n",
            "2022-06-09 21:21:52,458 epoch 5 - iter 184/232 - loss 0.30006079 - samples/sec: 407.56 - lr: 0.100000\n",
            "2022-06-09 21:21:54,279 epoch 5 - iter 207/232 - loss 0.29899335 - samples/sec: 405.12 - lr: 0.100000\n",
            "2022-06-09 21:21:56,179 epoch 5 - iter 230/232 - loss 0.29623061 - samples/sec: 388.31 - lr: 0.100000\n",
            "2022-06-09 21:21:56,300 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:21:56,302 EPOCH 5 done: loss 0.2969 - lr 0.100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74/74 [00:07<00:00, 10.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:22:03,677 Evaluating as a multi-label problem: False\n",
            "2022-06-09 21:22:03,709 DEV : loss 0.25249624252319336 - f1-score (micro avg)  0.4573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:22:03,865 BAD EPOCHS (no improvement): 0\n",
            "2022-06-09 21:22:03,870 saving best model\n",
            "2022-06-09 21:22:06,185 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:22:06,190 loading file resources/taggers/example-upos/best-model.pt\n",
            "2022-06-09 21:22:06,831 SequenceTagger predicts: Dictionary with 83 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Function, B-Function, E-Function, I-Function, S-Library, B-Library, E-Library, I-Library, S-Language, B-Language, E-Language, I-Language, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-Version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 78/78 [00:11<00:00,  6.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:22:18,268 Evaluating as a multi-label problem: False\n",
            "2022-06-09 21:22:18,306 0.4987\t0.4101\t0.4501\t0.3417\n",
            "2022-06-09 21:22:18,308 \n",
            "Results:\n",
            "- F-score (micro) 0.4501\n",
            "- F-score (macro) 0.3987\n",
            "- Accuracy 0.3417\n",
            "\n",
            "By class:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "                 Class     0.4469    0.4594    0.4531       394\n",
            "           Application     0.3986    0.5307    0.4553       326\n",
            "              Variable     0.2735    0.2075    0.2360       294\n",
            "User_Interface_Element     0.5263    0.4833    0.5039       269\n",
            "        Data_Structure     0.6995    0.7435    0.7208       191\n",
            "            Code_Block     0.3163    0.1216    0.1756       255\n",
            "               Library     0.4692    0.2976    0.3642       205\n",
            "              Function     0.5176    0.2157    0.3045       204\n",
            "              Language     0.7209    0.6691    0.6940       139\n",
            "             File_Name     0.6250    0.3937    0.4831       127\n",
            "             File_Type     0.5208    0.4902    0.5051       102\n",
            "               Version     0.8382    0.6196    0.7125        92\n",
            "             Data_Type     0.8226    0.6000    0.6939        85\n",
            "      Operating_System     0.5789    0.8000    0.6718        55\n",
            "                Device     0.3846    0.1351    0.2000        37\n",
            "          HTML_XML_Tag     0.6000    0.0682    0.1224        44\n",
            "               Website     0.5000    0.1935    0.2791        31\n",
            "             User_Name     0.0000    0.0000    0.0000        19\n",
            "             Algorithm     0.0000    0.0000    0.0000        13\n",
            "\n",
            "             micro avg     0.4987    0.4101    0.4501      2882\n",
            "             macro avg     0.4863    0.3699    0.3987      2882\n",
            "          weighted avg     0.4899    0.4101    0.4314      2882\n",
            "\n",
            "2022-06-09 21:22:18,309 ----------------------------------------------------------------------------------------------------\n",
            "2022-06-09 21:22:18,313 loading file resources/taggers/example-upos/final-model.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-09 21:22:18,853 SequenceTagger predicts: Dictionary with 83 tags: O, S-Application, B-Application, E-Application, I-Application, S-Class, B-Class, E-Class, I-Class, S-Variable, B-Variable, E-Variable, I-Variable, S-User_Interface_Element, B-User_Interface_Element, E-User_Interface_Element, I-User_Interface_Element, S-Code_Block, B-Code_Block, E-Code_Block, I-Code_Block, S-Function, B-Function, E-Function, I-Function, S-Library, B-Library, E-Library, I-Library, S-Language, B-Language, E-Language, I-Language, S-Data_Structure, B-Data_Structure, E-Data_Structure, I-Data_Structure, S-Data_Type, B-Data_Type, E-Data_Type, I-Data_Type, S-File_Type, B-File_Type, E-File_Type, I-File_Type, S-File_Name, B-File_Name, E-File_Name, I-File_Name, S-Version\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predykcja z udziałem modelu\n",
        "\n",
        "Jeśli model został wytrenowany, poniżej znajdziemy fragment kodu, który może wykryć encje w zdaniach."
      ],
      "metadata": {
        "id": "lxrd6m0H_-SJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downsample(0.1) wykryło \"Python\"/Language\n",
        "#Downsample(0.8) wykryło \"Python\"/Language, \"3\"/Version"
      ],
      "metadata": {
        "id": "O9mLRwG_RYA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "# Jeśli nasz model się wyuczył, powinien wykryć Python jako język.\n",
        "# Uwaga, ponieważ pracujemy na niewielkim podzbiorze zbioru danych (downsample(0.1) próbkuje 10%), \n",
        "# otrzymywane wyniki mogą być kiepskiej jakości, najlepiej zwiększyść ilość danych \n",
        "# jeśli pracujemy w domu.\n",
        "sentence = Sentence('huge files can be opened from Python 3.')   # stwórz obiekt zdania\n",
        "model.predict(sentence)                                         # wykryj encje nazwane\n",
        "print(sentence.to_tagged_string())                              # wyświetl zdanie i wykryte w nim encje"
      ],
      "metadata": {
        "id": "Koq76zqawM3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41958a48-9530-4117-e126-23dfbecf6dad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \"huge files can be opened from Python 3 .\" → [\"Python\"/Language, \"3\"/Version]\n"
          ]
        }
      ]
    }
  ]
}